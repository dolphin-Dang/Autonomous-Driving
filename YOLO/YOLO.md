[YOLO家族进化史v1-v7](https://zhuanlan.zhihu.com/p/539932517)

[YOLOv1-v8综述](https://blog.csdn.net/daydayup858/article/details/130018935)

# YOLOv1
如RCNN的目标检测算法都是2-stage的，效率相对低。

YOLO思路：
+ 通过CNN将图像提取特征图
+ 特征图输入全连接层
+ 将FC的输出reshape为 7*7*30 大小的特征图
+ 类似RPN的思路，7*7中每一个点负责一些物体的检测，
  + 预测20个类
  + 预测2个框，每个框用4个数表示
  + 20+2+2*4 = 30

优势：直接回归，速度快；不足：每个网格只预测2个框，如果物体有重叠就很难预测出来。

### 损失函数
[YOLO损失函数详解](https://blog.csdn.net/x454045816/article/details/107527326)

分为三个部分，都使用均方误差：
+ bbox位置误差
  + 使用超参数$\lambda_{coord}=5$来强化预测框的位置要求
  + 框的中心坐标使用正常均方误差，而宽度和高度使用开方之后的均方误差
    + 这是因为宽高比例一样的情况下，面积比例是平方倍；而如果希望以面积比衡量预测框准确与否，则需要开方
+ bbox置信度误差
  + 分为包含物体和不包含物体两部分
  + 不包含物体的损失用$\lambda_{noobj}=0.5$来弱化
+ 网格预测类别损失 

一切损失都是要求至少包含物体与否预测正确，才会计算损失。


# YOLOv2
[YOLOv2论文解读](https://zhuanlan.zhihu.com/p/124269512)

改动：
+ 更换骨干网络：darknet19
+ 引入 PassThrough
  + 类似残差连接，将前面某一层的输出调整大小之后与后面的输出concat
  + 使用高分辨率特征图可以更好地预测小物体
+ 借鉴 2-stage 思路，引入预选框
  + 使用RPN
  + 调整预测框的位置为预测框相对anchor的偏移量
  + 选择anchor：
    + 通过kmeans聚类训练集的标注框，距离指标为目标框和聚类中心框的IoU
    + 选择其中5个框，比之前的9个框少，效果差不多
    + 预测其左上角和宽高，比预测中心更稳定
+ 分类数据集和检测数据集联合训练

问题：小目标、密集多目标

# YOLOv3
改动：
+ 引入残差，把darknet19优化为darknet53
+ 特征金字塔，在三个不同的尺度上分别预测
  + 不同的是，将高级语义的小尺寸特征图上采样之后，按通道维度concat


